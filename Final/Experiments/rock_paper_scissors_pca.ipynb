{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoT5RmjYkt4J"
   },
   "source": [
    "## Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BhMhFCmtNCpW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow-transform\n",
      "  Using cached tensorflow_transform-1.4.0-py3-none-any.whl (413 kB)\n",
      "Collecting pydot<2,>=1.2\n",
      "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting pyarrow<6,>=1\n",
      "  Using cached pyarrow-5.0.0-cp38-cp38-manylinux2014_x86_64.whl (23.6 MB)\n",
      "Collecting tensorflow-metadata<1.5.0,>=1.4.0\n",
      "  Using cached tensorflow_metadata-1.4.0-py3-none-any.whl (48 kB)\n",
      "Collecting tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2\n",
      "  Downloading tensorflow-2.6.2-cp38-cp38-manylinux2010_x86_64.whl (458.4 MB)\n",
      "     |████████████████████████████████| 458.4 MB 33 kB/s              \n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.13 in /home/lawrence910426/.local/lib/python3.8/site-packages (from tensorflow-transform) (3.19.1)\n",
      "Collecting tfx-bsl<1.5.0,>=1.4.0\n",
      "  Downloading tfx_bsl-1.4.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (19.1 MB)\n",
      "     |████████████████████████████████| 19.1 MB 12.3 MB/s            \n",
      "\u001b[?25hCollecting absl-py<0.13,>=0.9\n",
      "  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting numpy<1.20,>=1.16\n",
      "  Using cached numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
      "Collecting apache-beam[gcp]<3,>=2.33\n",
      "  Using cached apache_beam-2.33.0-cp38-cp38-manylinux2010_x86_64.whl (11.6 MB)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from absl-py<0.13,>=0.9->tensorflow-transform) (1.14.0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/lib/python3/dist-packages (from apache-beam[gcp]<3,>=2.33->tensorflow-transform) (2019.3)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /home/lawrence910426/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.33->tensorflow-transform) (1.41.1)\n",
      "Collecting orjson<4.0\n",
      "  Downloading orjson-3.6.4-cp38-cp38-manylinux_2_24_x86_64.whl (249 kB)\n",
      "     |████████████████████████████████| 249 kB 52.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/lib/python3/dist-packages (from apache-beam[gcp]<3,>=2.33->tensorflow-transform) (0.14.0)\n",
      "Collecting avro-python3!=1.9.2,<1.10.0,>=1.8.1\n",
      "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "     |████████████████████████████████| 151 kB 11.2 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyarrow<6,>=1\n",
      "  Downloading pyarrow-4.0.1-cp38-cp38-manylinux2014_x86_64.whl (21.9 MB)\n",
      "     |████████████████████████████████| 21.9 MB 12.2 MB/s            \n",
      "\u001b[?25hCollecting oauth2client<5,>=2.0.1\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "     |████████████████████████████████| 98 kB 7.1 MB/s             \n",
      "\u001b[?25hCollecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "     |████████████████████████████████| 89 kB 6.1 MB/s             \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: future<1.0.0,>=0.18.2 in /usr/lib/python3/dist-packages (from apache-beam[gcp]<3,>=2.33->tensorflow-transform) (0.18.2)\n",
      "Collecting python-dateutil<3,>=2.8.0\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     |████████████████████████████████| 247 kB 12.3 MB/s            \n",
      "\u001b[?25hCollecting fastavro<2,>=0.21.4\n",
      "  Downloading fastavro-1.4.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "     |████████████████████████████████| 2.6 MB 65.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<4,>=3.7.0 in /home/lawrence910426/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.33->tensorflow-transform) (3.10.0.2)\n",
      "Collecting requests<3.0.0,>=2.24.0\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "     |████████████████████████████████| 62 kB 2.0 MB/s             \n",
      "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.12.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (527 kB)\n",
      "     |████████████████████████████████| 527 kB 11.2 MB/s            \n",
      "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
      "Collecting grpcio-gcp<1,>=0.2.2\n",
      "  Downloading grpcio_gcp-0.2.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: cachetools<5,>=3.1.0 in /home/lawrence910426/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.33->tensorflow-transform) (4.2.4)\n",
      "Collecting google-cloud-language<2,>=1.3.0\n",
      "  Downloading google_cloud_language-1.3.0-py2.py3-none-any.whl (83 kB)\n",
      "     |████████████████████████████████| 83 kB 2.9 MB/s             \n",
      "\u001b[?25hCollecting google-cloud-datastore<2,>=1.8.0\n",
      "  Downloading google_cloud_datastore-1.15.3-py2.py3-none-any.whl (134 kB)\n",
      "     |████████████████████████████████| 134 kB 10.0 MB/s            \n",
      "\u001b[?25hCollecting google-cloud-dlp<2,>=0.12.0\n",
      "  Downloading google_cloud_dlp-1.0.0-py2.py3-none-any.whl (169 kB)\n",
      "     |████████████████████████████████| 169 kB 11.1 MB/s            \n",
      "\u001b[?25hCollecting google-cloud-vision<2,>=0.38.0\n",
      "  Downloading google_cloud_vision-1.0.0-py2.py3-none-any.whl (435 kB)\n",
      "     |████████████████████████████████| 435 kB 11.1 MB/s            \n",
      "\u001b[?25hCollecting google-cloud-core<2,>=0.28.1\n",
      "  Downloading google_cloud_core-1.7.2-py2.py3-none-any.whl (28 kB)\n",
      "Collecting google-cloud-bigquery<3,>=1.6.0\n",
      "  Downloading google_cloud_bigquery-2.30.1-py2.py3-none-any.whl (203 kB)\n",
      "     |████████████████████████████████| 203 kB 11.1 MB/s            \n",
      "\u001b[?25hCollecting google-cloud-bigtable<2,>=0.31.1\n",
      "  Downloading google_cloud_bigtable-1.7.0-py2.py3-none-any.whl (267 kB)\n",
      "     |████████████████████████████████| 267 kB 11.1 MB/s            \n",
      "\u001b[?25hCollecting google-cloud-recommendations-ai<=0.2.0,>=0.1.0\n",
      "  Downloading google_cloud_recommendations_ai-0.2.0-py2.py3-none-any.whl (180 kB)\n",
      "     |████████████████████████████████| 180 kB 11.3 MB/s            \n",
      "\u001b[?25hCollecting google-cloud-pubsub<2,>=0.39.0\n",
      "  Downloading google_cloud_pubsub-1.7.0-py2.py3-none-any.whl (144 kB)\n",
      "     |████████████████████████████████| 144 kB 11.0 MB/s            \n",
      "\u001b[?25hCollecting google-cloud-videointelligence<2,>=1.8.0\n",
      "  Downloading google_cloud_videointelligence-1.16.1-py2.py3-none-any.whl (183 kB)\n",
      "     |████████████████████████████████| 183 kB 5.8 MB/s            \n",
      "\u001b[?25hCollecting google-apitools<0.5.32,>=0.5.31\n",
      "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
      "     |████████████████████████████████| 173 kB 10.4 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting google-cloud-spanner<2,>=1.13.0\n",
      "  Downloading google_cloud_spanner-1.19.1-py2.py3-none-any.whl (255 kB)\n",
      "     |████████████████████████████████| 255 kB 11.3 MB/s            \n",
      "\u001b[?25hCollecting google-auth<2,>=1.18.0\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "     |████████████████████████████████| 152 kB 10.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.4 in /home/lawrence910426/.local/lib/python3.8/site-packages (from pydot<2,>=1.2->tensorflow-transform) (2.4.7)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "     |████████████████████████████████| 462 kB 13.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: gast==0.4.0 in /home/lawrence910426/.local/lib/python3.8/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (0.4.0)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /home/lawrence910426/.local/lib/python3.8/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (1.1.2)\n",
      "Collecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "     |████████████████████████████████| 5.6 MB 10.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /home/lawrence910426/.local/lib/python3.8/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/lawrence910426/.local/lib/python3.8/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (1.6.3)\n",
      "Collecting keras<2.7,>=2.6.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 11.1 MB/s            \n",
      "\u001b[?25hCollecting six\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "     |████████████████████████████████| 4.4 MB 7.8 MB/s            \n",
      "\u001b[?25hCollecting wheel~=0.35\n",
      "  Downloading wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/lawrence910426/.local/lib/python3.8/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (0.2.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/lawrence910426/.local/lib/python3.8/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (1.1.0)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing-extensions<4,>=3.7.0\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "     |████████████████████████████████| 198 kB 11.1 MB/s            \n",
      "\u001b[?25hCollecting pandas<2,>=1.0\n",
      "  Downloading pandas-1.3.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "     |████████████████████████████████| 11.5 MB 864 kB/s             \n",
      "\u001b[?25hCollecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15\n",
      "  Downloading tensorflow_serving_api-2.7.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting google-api-python-client<2,>=1.7.11\n",
      "  Downloading google_api_python_client-1.12.8-py2.py3-none-any.whl (61 kB)\n",
      "     |████████████████████████████████| 61 kB 63 kB/s              \n",
      "\u001b[?25hCollecting httplib2<0.20.0,>=0.8\n",
      "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "     |████████████████████████████████| 95 kB 4.4 MB/s             \n",
      "\u001b[?25hCollecting google-api-core<2dev,>=1.21.0\n",
      "  Downloading google_api_core-1.31.4-py2.py3-none-any.whl (93 kB)\n",
      "     |████████████████████████████████| 93 kB 2.4 MB/s             \n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.0.3\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting uritemplate<4dev,>=3.0.0\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: fasteners>=0.14 in /usr/lib/python3/dist-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.33->tensorflow-transform) (0.14.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/lawrence910426/.local/lib/python3.8/site-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]<3,>=2.33->tensorflow-transform) (4.7.2)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]<3,>=2.33->tensorflow-transform) (45.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/lawrence910426/.local/lib/python3.8/site-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]<3,>=2.33->tensorflow-transform) (0.2.8)\n",
      "Collecting proto-plus>=1.10.0\n",
      "  Downloading proto_plus-1.19.8-py3-none-any.whl (45 kB)\n",
      "     |████████████████████████████████| 45 kB 6.4 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: packaging>=14.3 in /home/lawrence910426/.local/lib/python3.8/site-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.33->tensorflow-transform) (21.2)\n",
      "Collecting google-resumable-media<3.0dev,>=0.6.0\n",
      "  Downloading google_resumable_media-2.1.0-py2.py3-none-any.whl (75 kB)\n",
      "     |████████████████████████████████| 75 kB 5.1 MB/s             \n",
      "\u001b[?25hCollecting google-api-core[grpc]<3.0.0dev,>=1.29.0\n",
      "  Downloading google_api_core-2.2.2-py2.py3-none-any.whl (95 kB)\n",
      "     |████████████████████████████████| 95 kB 4.7 MB/s             \n",
      "\u001b[?25hCollecting grpc-google-iam-v1<0.13dev,>=0.12.3\n",
      "  Downloading grpc-google-iam-v1-0.12.3.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /home/lawrence910426/.local/lib/python3.8/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.33->tensorflow-transform) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.33->tensorflow-transform) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.33->tensorflow-transform) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.33->tensorflow-transform) (2.8)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.7-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/lawrence910426/.local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/lawrence910426/.local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/lawrence910426/.local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/lawrence910426/.local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/lawrence910426/.local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (2.0.2)\n",
      "Collecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15\n",
      "  Downloading tensorflow_serving_api-2.6.2-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/lawrence910426/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (1.3.0)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.3.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (37 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2->tensorflow-transform) (3.1.0)\n",
      "Building wheels for collected packages: avro-python3, clang, crcmod, dill, google-apitools, wrapt, grpc-google-iam-v1, docopt\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43513 sha256=181a1ef8bd4db6dbd41e019cb03c8f8522651560c40ea3c5d204887cd04f6894\n",
      "  Stored in directory: /home/lawrence910426/.cache/pip/wheels/a5/f2/87/b7c4b9d5915716d94e8bf2e2f3bfbbd73bb5fe2a98677a59cb\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=716bcb6676f7339d11af0efb18363027b827ad79d7f36a2d59c005a05a51cc10\n",
      "  Stored in directory: /home/lawrence910426/.cache/pip/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp38-cp38-linux_x86_64.whl size=36028 sha256=836ff06198695697f537d0b616052f08e0c0e7239f2bb0f12be0ebbb3e2022af\n",
      "  Stored in directory: /home/lawrence910426/.cache/pip/wheels/ca/5a/02/f3acf982a026f3319fb3e798a8dca2d48fafee7761788562e9\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=3d59ff6c4095dd577eae4ed523b22fbc6bc75310187918a8d5b5fe5f7759aba8\n",
      "  Stored in directory: /home/lawrence910426/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
      "  Building wheel for google-apitools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131042 sha256=c9bfcc80e7b7e817708b4e3313aaa47dedb9c06c9ab77a4161286697af368f72\n",
      "  Stored in directory: /home/lawrence910426/.cache/pip/wheels/d7/54/79/85de1824f2f4175fb4960c72afb10045d86700c3941dc73685\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=78565 sha256=9a3d01eddf77ad248061e926b8e18987a13dee831c4087fbb58a78b6df92ba50\n",
      "  Stored in directory: /home/lawrence910426/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grpc-google-iam-v1: filename=grpc_google_iam_v1-0.12.3-py3-none-any.whl size=18483 sha256=1885e5ea8273494a4a845a59fb4b49e053b378dc4208d2dac253b617b0b4fd43\n",
      "  Stored in directory: /home/lawrence910426/.cache/pip/wheels/8f/b9/13/fce3d62261f63c01b28281fe6a9d704a7af65d96ff2c88552e\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=3efa53898e601d0d01d7eb83e046527d6aa412d3f7ebf70ca1d8a4da7b5972b5\n",
      "  Stored in directory: /home/lawrence910426/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built avro-python3 clang crcmod dill google-apitools wrapt grpc-google-iam-v1 docopt\n",
      "Installing collected packages: charset-normalizer, six, requests, googleapis-common-protos, google-auth, wheel, numpy, httplib2, grpcio-gcp, google-crc32c, google-api-core, docopt, absl-py, wrapt, typing-extensions, tensorflow-estimator, tensorboard, python-dateutil, pymongo, pydot, pyarrow, proto-plus, orjson, oauth2client, keras, hdfs, h5py, grpc-google-iam-v1, google-resumable-media, google-cloud-core, flatbuffers, fastavro, dill, crcmod, clang, avro-python3, uritemplate, tensorflow, google-cloud-vision, google-cloud-videointelligence, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-pubsub, google-cloud-language, google-cloud-dlp, google-cloud-datastore, google-cloud-bigtable, google-cloud-bigquery, google-auth-httplib2, google-apitools, apache-beam, tensorflow-serving-api, tensorflow-metadata, pandas, google-api-python-client, tfx-bsl, tensorflow-transform\n",
      "\u001b[33m  WARNING: The script normalizer is installed in '/home/lawrence910426/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.3.3\n",
      "    Uninstalling google-auth-2.3.3:\n",
      "      Successfully uninstalled google-auth-2.3.3\n",
      "\u001b[33m  WARNING: The script wheel is installed in '/home/lawrence910426/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.4\n",
      "    Uninstalling numpy-1.21.4:\n",
      "      Successfully uninstalled numpy-1.21.4\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.8 are installed in '/home/lawrence910426/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.15.0\n",
      "    Uninstalling absl-py-0.15.0:\n",
      "      Successfully uninstalled absl-py-0.15.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.13.3\n",
      "    Uninstalling wrapt-1.13.3:\n",
      "      Successfully uninstalled wrapt-1.13.3\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.7.0\n",
      "    Uninstalling tensorflow-estimator-2.7.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.7.0\n",
      "    Uninstalling tensorboard-2.7.0:\n",
      "      Successfully uninstalled tensorboard-2.7.0\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/lawrence910426/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\n",
      "\u001b[33m  WARNING: The script plasma_store is installed in '/home/lawrence910426/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.7.0\n",
      "    Uninstalling keras-2.7.0:\n",
      "      Successfully uninstalled keras-2.7.0\n",
      "\u001b[33m  WARNING: The scripts hdfscli and hdfscli-avro are installed in '/home/lawrence910426/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.5.0\n",
      "    Uninstalling h5py-3.5.0:\n",
      "      Successfully uninstalled h5py-3.5.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 2.0\n",
      "    Uninstalling flatbuffers-2.0:\n",
      "      Successfully uninstalled flatbuffers-2.0\n",
      "\u001b[33m  WARNING: The script fastavro is installed in '/home/lawrence910426/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.7.0\n",
      "    Uninstalling tensorflow-2.7.0:\n",
      "      Successfully uninstalled tensorflow-2.7.0\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/lawrence910426/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\n",
      "\u001b[33m  WARNING: The script gen_client is installed in '/home/lawrence910426/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "launchpadlib 1.10.13 requires testresources, which is not installed.\u001b[0m\n",
      "Successfully installed absl-py-0.12.0 apache-beam-2.33.0 avro-python3-1.9.2.1 charset-normalizer-2.0.7 clang-5.0 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-1.4.7 flatbuffers-1.12 google-api-core-1.31.4 google-api-python-client-1.12.8 google-apitools-0.5.31 google-auth-1.35.0 google-auth-httplib2-0.1.0 google-cloud-bigquery-2.30.1 google-cloud-bigtable-1.7.0 google-cloud-core-1.7.2 google-cloud-datastore-1.15.3 google-cloud-dlp-1.0.0 google-cloud-language-1.3.0 google-cloud-pubsub-1.7.0 google-cloud-recommendations-ai-0.2.0 google-cloud-spanner-1.19.1 google-cloud-videointelligence-1.16.1 google-cloud-vision-1.0.0 google-crc32c-1.3.0 google-resumable-media-2.1.0 googleapis-common-protos-1.53.0 grpc-google-iam-v1-0.12.3 grpcio-gcp-0.2.2 h5py-3.1.0 hdfs-2.6.0 httplib2-0.19.1 keras-2.6.0 numpy-1.19.5 oauth2client-4.1.3 orjson-3.6.4 pandas-1.3.4 proto-plus-1.19.8 pyarrow-4.0.1 pydot-1.4.2 pymongo-3.12.1 python-dateutil-2.8.2 requests-2.26.0 six-1.15.0 tensorboard-2.6.0 tensorflow-2.6.2 tensorflow-estimator-2.6.0 tensorflow-metadata-1.4.0 tensorflow-serving-api-2.6.2 tensorflow-transform-1.4.0 tfx-bsl-1.4.0 typing-extensions-3.7.4.3 uritemplate-3.0.1 wheel-0.37.0 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "# Selecting Tensorflow version v2 (the command is relevant for Colab only).\n",
    "# %tensorflow_version 2.x\n",
    "# !pip install -U tfx\n",
    "!pip3 install tensorflow-transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWnwUtAmLt1B"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import platform\n",
    "import datetime\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "print('Python version:', platform.python_version())\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "print('Keras version:', tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eARhRY8PLt1u"
   },
   "source": [
    "## Configuring TensorBoard\n",
    "\n",
    "We will use TensorBoard as a helper to debug the model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLxzq_peLt1z"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "# %reload_ext tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2ms5YLpLt13"
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs.\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9YXAy5kLt18"
   },
   "source": [
    "## Loading the dataset\n",
    "\n",
    "We will download Rock-Paper-Scissors dataset from [TensorFlow Datasets](https://github.com/tensorflow/datasets) collection. To do that we loaded a `tensorflow_datasets` module.\n",
    "\n",
    "`tensorflow_datasets` defines a collection of datasets ready-to-use with TensorFlow.\n",
    "\n",
    "Each dataset is defined as a [tfds.core.DatasetBuilder](https://www.tensorflow.org/datasets/api_docs/python/tfds/core/DatasetBuilder), which encapsulates the logic to download the dataset and construct an input pipeline, as well as contains the dataset documentation (version, splits, number of examples, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2zZOCweLt1-"
   },
   "outputs": [],
   "source": [
    "# See available datasets\n",
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxDymXbpLt2D"
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = 'rock_paper_scissors'\n",
    "\n",
    "(dataset_train_raw, dataset_test_raw), dataset_info = tfds.load(\n",
    "    name=DATASET_NAME,\n",
    "    data_dir='tmp',\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    split=[tfds.Split.TRAIN, tfds.Split.TEST],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMRaImcqLt2H"
   },
   "outputs": [],
   "source": [
    "print('Raw train dataset:', dataset_train_raw)\n",
    "print('Raw train dataset size:', len(list(dataset_train_raw)), '\\n')\n",
    "\n",
    "print('Raw test dataset:', dataset_test_raw)\n",
    "print('Raw test dataset size:', len(list(dataset_test_raw)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5pZ7fwnLt3V"
   },
   "outputs": [],
   "source": [
    "dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvRfxFpN67yh"
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN_EXAMPLES = dataset_info.splits['train'].num_examples\n",
    "NUM_TEST_EXAMPLES = dataset_info.splits['test'].num_examples\n",
    "NUM_CLASSES = dataset_info.features['label'].num_classes\n",
    "\n",
    "print('Number of TRAIN examples:', NUM_TRAIN_EXAMPLES)\n",
    "print('Number of TEST examples:', NUM_TEST_EXAMPLES)\n",
    "print('Number of label classes:', NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuvV63gyLt3b"
   },
   "outputs": [],
   "source": [
    "INPUT_IMG_SIZE_ORIGINAL = dataset_info.features['image'].shape[0]\n",
    "INPUT_IMG_SHAPE_ORIGINAL = dataset_info.features['image'].shape\n",
    "\n",
    "INPUT_IMG_SIZE_REDUCED = INPUT_IMG_SIZE_ORIGINAL // 12\n",
    "INPUT_IMG_SHAPE_REDUCED = (\n",
    "    INPUT_IMG_SIZE_REDUCED,\n",
    "    INPUT_IMG_SIZE_REDUCED,\n",
    "    INPUT_IMG_SHAPE_ORIGINAL[2]\n",
    ")\n",
    "\n",
    "# Here we may switch between bigger or smaller image sized that we will train our model on.\n",
    "INPUT_IMG_SIZE = INPUT_IMG_SIZE_REDUCED\n",
    "INPUT_IMG_SHAPE = INPUT_IMG_SHAPE_REDUCED\n",
    "\n",
    "print('Input image size (original):', INPUT_IMG_SIZE_ORIGINAL)\n",
    "print('Input image shape (original):', INPUT_IMG_SHAPE_ORIGINAL)\n",
    "print('\\n')\n",
    "print('Input image size (reduced):', INPUT_IMG_SIZE_REDUCED)\n",
    "print('Input image shape (reduced):', INPUT_IMG_SHAPE_REDUCED)\n",
    "print('\\n')\n",
    "print('Input image size:', INPUT_IMG_SIZE)\n",
    "print('Input image shape:', INPUT_IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbSOb5p4Lt3q"
   },
   "outputs": [],
   "source": [
    "# Function to convert label ID to labels string.\n",
    "get_label_name = dataset_info.features['label'].int2str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fef-jl8qLt3u"
   },
   "outputs": [],
   "source": [
    "print(get_label_name(0));\n",
    "print(get_label_name(1));\n",
    "print(get_label_name(2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--UTznQZLt5r"
   },
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_MA0RMTLt5s"
   },
   "outputs": [],
   "source": [
    "def preview_dataset(dataset):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plot_index = 0\n",
    "    for features in dataset.take(12):\n",
    "        (image, label) = features\n",
    "        plot_index += 1\n",
    "        plt.subplot(3, 4, plot_index)\n",
    "        # plt.axis('Off')\n",
    "        label = get_label_name(label.numpy())\n",
    "        plt.title('Label: %s' % label)\n",
    "        plt.imshow(image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-0-ntBmLt5x"
   },
   "outputs": [],
   "source": [
    "# Explore raw training dataset images.\n",
    "preview_dataset(dataset_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADqRAQ2YLt6E"
   },
   "outputs": [],
   "source": [
    "# Explore what values are used to represent the image. \n",
    "(first_image, first_lable) = list(dataset_train_raw.take(1))[0]\n",
    "print('Label:', first_lable.numpy(), '\\n')\n",
    "print('Image shape:', first_image.numpy().shape, '\\n')\n",
    "print(first_image.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuUdSSzoLt6I"
   },
   "source": [
    "## Pre-processing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onNMq8CQLt6J"
   },
   "outputs": [],
   "source": [
    "def format_example(image, label):\n",
    "    # Make image color values to be float.\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Make image color values to be in [0..1] range.\n",
    "    image = image / 255.\n",
    "    # Make sure that image has a right size\n",
    "    image = tf.image.resize(image, [INPUT_IMG_SIZE, INPUT_IMG_SIZE])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUxjRhVpLt6M"
   },
   "outputs": [],
   "source": [
    "dataset_train = dataset_train_raw.map(format_example)\n",
    "dataset_test = dataset_test_raw.map(format_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0QPUYQfLt6R"
   },
   "outputs": [],
   "source": [
    "# Explore what values are used to represent the image. \n",
    "(first_image, first_lable) = list(dataset_train.take(1))[0]\n",
    "print('Label:', first_lable.numpy(), '\\n')\n",
    "print('Image shape:', first_image.numpy().shape, '\\n')\n",
    "print(first_image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7SYQ7kELt6U"
   },
   "outputs": [],
   "source": [
    "# Explore preprocessed training dataset images.\n",
    "preview_dataset(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vojj1CCnLt6Y"
   },
   "source": [
    "## Data augmentation\n",
    "\n",
    "One of the way to fight the [model overfitting](https://en.wikipedia.org/wiki/Overfitting) and to generalize the model to a broader set of examples is to augment the training data.\n",
    "\n",
    "As you saw from the previous section all training examples have a white background and vertically positioned right hands. But what if the image with the hand will be horizontally positioned or what if the background will not be that bright. What if instead of a right hand the model will see a left hand. To make our model a little bit more universal we're going to flip and rotate images and also to adjust background colors.   \n",
    "\n",
    "You may read more about a [Simple and efficient data augmentations using the Tensorfow tf.Data and Dataset API](https://www.wouterbulten.nl/blog/tech/data-augmentation-using-tensorflow-data-dataset/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsHN6_40_L-a"
   },
   "outputs": [],
   "source": [
    "def augment_flip(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nzkXAMa-5ZG"
   },
   "outputs": [],
   "source": [
    "def augment_color(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.random_hue(image, max_delta=0.08)\n",
    "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)\n",
    "    image = tf.image.random_brightness(image, 0.05)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1)\n",
    "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeF-o0X0ARj0"
   },
   "outputs": [],
   "source": [
    "def augment_rotation(image: tf.Tensor) -> tf.Tensor:\n",
    "    # Rotate 0, 90, 180, 270 degrees\n",
    "    return tf.image.rot90(\n",
    "        image,\n",
    "        tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SK9mlrfVua7L"
   },
   "outputs": [],
   "source": [
    "def augment_inversion(image: tf.Tensor) -> tf.Tensor:\n",
    "    random = tf.random.uniform(shape=[], minval=0, maxval=1)\n",
    "    if random > 0.5:\n",
    "        image = tf.math.multiply(image, -1)\n",
    "        image = tf.math.add(image, 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfVxVWSOAyPq"
   },
   "outputs": [],
   "source": [
    "def augment_zoom(image: tf.Tensor, min_zoom=0.8, max_zoom=1.0) -> tf.Tensor:\n",
    "    image_width, image_height, image_colors = image.shape\n",
    "    crop_size = (image_width, image_height)\n",
    "\n",
    "    # Generate crop settings, ranging from a 1% to 20% crop.\n",
    "    scales = list(np.arange(min_zoom, max_zoom, 0.01))\n",
    "    boxes = np.zeros((len(scales), 4))\n",
    "\n",
    "    for i, scale in enumerate(scales):\n",
    "        x1 = y1 = 0.5 - (0.5 * scale)\n",
    "        x2 = y2 = 0.5 + (0.5 * scale)\n",
    "        boxes[i] = [x1, y1, x2, y2]\n",
    "\n",
    "    def random_crop(img):\n",
    "        # Create different crops for an image\n",
    "        crops = tf.image.crop_and_resize(\n",
    "            [img],\n",
    "            boxes=boxes,\n",
    "            box_indices=np.zeros(len(scales)),\n",
    "            crop_size=crop_size\n",
    "        )\n",
    "        # Return a random crop\n",
    "        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
    "\n",
    "    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "\n",
    "    # Only apply cropping 50% of the time\n",
    "    return tf.cond(choice < 0.5, lambda: image, lambda: random_crop(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eD9cluIhLt6Y"
   },
   "outputs": [],
   "source": [
    "def augment_data(image, label):\n",
    "    image = augment_flip(image)\n",
    "    image = augment_color(image)\n",
    "    image = augment_rotation(image)\n",
    "    image = augment_zoom(image)\n",
    "    image = augment_inversion(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eceiqwBKLt72"
   },
   "outputs": [],
   "source": [
    "dataset_train_augmented = dataset_train.map(augment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRyHTdQhLt8C"
   },
   "outputs": [],
   "source": [
    "# Explore augmented training dataset.\n",
    "preview_dataset(dataset_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PliJJvraV0w-"
   },
   "outputs": [],
   "source": [
    "# Explore test dataset.\n",
    "preview_dataset(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBTbwiPYLt8G"
   },
   "source": [
    "## Data shuffling and batching\n",
    "\n",
    "We don't want our model to learn anything from the order or grouping of the images in the dataset. To avoid that we will shuffle the training examples. Also we're going to split the training set by batches to speed up training process and make it less memory consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCWeWR5QLt8H"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset_train_augmented_shuffled = dataset_train_augmented.shuffle(\n",
    "    buffer_size=NUM_TRAIN_EXAMPLES\n",
    ")\n",
    "\n",
    "dataset_train_augmented_shuffled = dataset_train_augmented.batch(\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Prefetch will enable the input pipeline to asynchronously fetch batches while your model is training.\n",
    "dataset_train_augmented_shuffled = dataset_train_augmented_shuffled.prefetch(\n",
    "    buffer_size=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "\n",
    "dataset_test_shuffled = dataset_test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiXw2QMxLt8K"
   },
   "outputs": [],
   "source": [
    "print(dataset_train_augmented_shuffled)\n",
    "print(dataset_test_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBQW_0i5Lt8W"
   },
   "outputs": [],
   "source": [
    "# Debugging the batches using conversion to Numpy arrays.\n",
    "batches = tfds.as_numpy(dataset_train_augmented_shuffled)\n",
    "for batch in batches:\n",
    "    image_batch, label_batch = batch\n",
    "    print('Label batch shape:', label_batch.shape, '\\n')\n",
    "    print('Image batch shape:', image_batch.shape, '\\n')\n",
    "    print('Label batch:', label_batch, '\\n')\n",
    "    \n",
    "    for batch_item_index in range(len(image_batch)):\n",
    "        print('First batch image:', image_batch[batch_item_index], '\\n')\n",
    "        plt.imshow(image_batch[batch_item_index])\n",
    "        plt.show()\n",
    "        # Break to shorten the output.\n",
    "        break\n",
    "    # Break to shorten the output.\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hz_hZSCULt8Z"
   },
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucf9419Ks4YD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tfx import v1 as tfx\n",
    "import tensorflow_transform as tft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3DBp9ATANdF"
   },
   "outputs": [],
   "source": [
    "dataset = np.array(list(dataset_train_augmented))\n",
    "dataset = np.array([dataset[i, 0] for i in range(dataset.shape[0])])\n",
    "print(dataset.shape)\n",
    "\n",
    "dataset = np.reshape(\n",
    "    dataset, \n",
    "    (dataset.shape[0], INPUT_IMG_SIZE_REDUCED * INPUT_IMG_SIZE_REDUCED * 3)\n",
    ")\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "executionInfo": {
     "elapsed": 633710,
     "status": "ok",
     "timestamp": 1636642243584,
     "user": {
      "displayName": "吳邦寧",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03292217645448759712"
     },
     "user_tz": -480
    },
    "id": "8S-x1TlNq6T5"
   },
   "outputs": [],
   "source": [
    "class PcaLayer(keras.layers.Layer):\n",
    "    def __init__(self, x, dims):\n",
    "      super(PcaLayer, self).__init__()\n",
    "\n",
    "      x_std = (x - np.mean(x, axis=0)) / np.std(x, axis=0)\n",
    "      cov = np.cov(x_std.T)\n",
    "      pca = np.zeros((dataset.shape[1], dims), dtype=np.float32)\n",
    "      for i in range(dims):\n",
    "        ev, eig = np.linalg.eig(cov)\n",
    "        eig = eig[0]\n",
    "        eig = np.reshape(eig, (eig.shape[0]))\n",
    "        cov = cov - eig * eig.T * cov\n",
    "        pca[:,i] = eig\n",
    "      self.pca = pca\n",
    "    \n",
    "    def call(self, inputs):\n",
    "      return tf.matmul(inputs, self.pca)\n",
    "\n",
    "    def get_config(self):\n",
    "      config = super().get_config().copy()\n",
    "      config.update({\n",
    "          'pca': self.pca\n",
    "      })\n",
    "      return config\n",
    "\n",
    "Pca = PcaLayer(dataset, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1636642243589,
     "user": {
      "displayName": "吳邦寧",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03292217645448759712"
     },
     "user_tz": -480
    },
    "id": "k4cHfXyQLt8a"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Flatten the results to feed into dense layers.\n",
    "model.add(tf.keras.layers.Flatten(\n",
    "    input_shape=INPUT_IMG_SHAPE\n",
    "))\n",
    "model.add(Pca)\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# dense layer.\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=64,\n",
    "    activation=tf.keras.activations.relu\n",
    "))\n",
    "\n",
    "# Output layer.\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=NUM_CLASSES,\n",
    "    activation=tf.keras.activations.softmax\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1636642243590,
     "user": {
      "displayName": "吳邦寧",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03292217645448759712"
     },
     "user_tz": -480
    },
    "id": "n2Kp94HfLt8e"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1636642243590,
     "user": {
      "displayName": "吳邦寧",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03292217645448759712"
     },
     "user_tz": -480
    },
    "id": "VGiEAOgWLt8m"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJcmE__0Lt8r"
   },
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1636642243590,
     "user": {
      "displayName": "吳邦寧",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03292217645448759712"
     },
     "user_tz": -480
    },
    "id": "DJ8jGFnTLt8t"
   },
   "outputs": [],
   "source": [
    "# adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "rmsprop_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=rmsprop_optimizer,\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p76LZoDiLt9r"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1636642243947,
     "user": {
      "displayName": "吳邦寧",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03292217645448759712"
     },
     "user_tz": -480
    },
    "id": "yZJIp8qELt9s"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // BATCH_SIZE\n",
    "validation_steps = NUM_TEST_EXAMPLES // BATCH_SIZE\n",
    "\n",
    "print('steps_per_epoch:', steps_per_epoch)\n",
    "print('validation_steps:', validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1636642243948,
     "user": {
      "displayName": "吳邦寧",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03292217645448759712"
     },
     "user_tz": -480
    },
    "id": "-D2etjoyPZTE"
   },
   "outputs": [],
   "source": [
    "!rm -rf tmp/checkpoints\n",
    "!rm -rf logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1636642243948,
     "user": {
      "displayName": "吳邦寧",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03292217645448759712"
     },
     "user_tz": -480
    },
    "id": "vG95ZXoLLt92"
   },
   "outputs": [],
   "source": [
    "# Preparing callbacks.\n",
    "os.makedirs('logs/fit', exist_ok=True)\n",
    "tensorboard_log_dir = 'logs/fit/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=tensorboard_log_dir,\n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "os.makedirs('tmp/checkpoints', exist_ok=True)\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='tmp/checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    ")\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    monitor='val_accuracy'\n",
    "    # monitor='val_loss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ppHB7fNLt-a",
    "outputId": "f8205d26-174d-4417-f1cb-cf70b838d5df"
   },
   "outputs": [],
   "source": [
    "training_history = model.fit(\n",
    "    x=dataset_train_augmented_shuffled.repeat(),\n",
    "    validation_data=dataset_test_shuffled.repeat(),\n",
    "    epochs=15,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[\n",
    "        # model_checkpoint_callback,\n",
    "        # early_stopping_callback,\n",
    "        tensorboard_callback\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "enF9trDLnDOI"
   },
   "outputs": [],
   "source": [
    "def render_training_history(training_history):\n",
    "    loss = training_history.history['loss']\n",
    "    val_loss = training_history.history['val_loss']\n",
    "\n",
    "    accuracy = training_history.history['accuracy']\n",
    "    val_accuracy = training_history.history['val_accuracy']\n",
    "\n",
    "    plt.figure(figsize=(14, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(loss, label='Training set')\n",
    "    plt.plot(val_loss, label='Test set', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(accuracy, label='Training set')\n",
    "    plt.plot(val_accuracy, label='Test set', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XSXmInPTLt-n"
   },
   "outputs": [],
   "source": [
    "render_training_history(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ubd3vQXuLt-v"
   },
   "source": [
    "## Debugging the training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gxHx2Bu9Lt-v"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmcefwvctykA"
   },
   "source": [
    "## Evaluating model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VwA0C3ZEt1X-"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "train_loss, train_accuracy = model.evaluate(\n",
    "    x=dataset_train.batch(BATCH_SIZE).take(NUM_TRAIN_EXAMPLES)\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    x=dataset_test.batch(BATCH_SIZE).take(NUM_TEST_EXAMPLES)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3CikvwUBwUVZ"
   },
   "outputs": [],
   "source": [
    "print('Training loss: ', train_loss)\n",
    "print('Training accuracy: ', train_accuracy)\n",
    "print('\\n')\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dOzgOVT1KFd"
   },
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3APy_0-1LvQ"
   },
   "outputs": [],
   "source": [
    "model_name = 'rock_paper_scissors_pca.h5'\n",
    "model.save(model_name, save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpRWiLQy-sd5"
   },
   "source": [
    "## Converting the model to web-format\n",
    "\n",
    "To use this model on the web we need to convert it into the format that will be understandable by [tensorflowjs](https://www.tensorflow.org/js). To do so we may use [tfjs-converter](https://github.com/tensorflow/tfjs/tree/master/tfjs-converter) as following:\n",
    "\n",
    "```\n",
    "tensorflowjs_converter --input_format keras \\\n",
    "  ./experiments/rock_paper_scissors_cnn/rock_paper_scissors_cnn.h5 \\\n",
    "  ./demos/public/models/rock_paper_scissors_cnn\n",
    "```\n",
    "\n",
    "You find this experiment in the [Demo app](https://trekhleb.github.io/machine-learning-experiments) and play around with it right in you browser to see how the model performs in real life."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rock_paper_scissors_pca.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/trekhleb/machine-learning-experiments/blob/master/experiments/rock_paper_scissors_cnn/rock_paper_scissors_cnn.ipynb",
     "timestamp": 1635923047966
    }
   ],
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
